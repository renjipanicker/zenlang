#include "zenlang.hpp"
#include "base/base.hpp"
#include "base/factory.hpp"
#include "base/lexer.hpp"
#include "parserGen.h"

// the char width could be 8 bit, 16, or 32 in future.
typedef char inputChar_t;

class z::Lexer::Impl {
public:
    inline Impl(Parser& parser);
    inline ~Impl();
    void push(ParserContext& pctx, const char* _buffer, std::streamsize len, const bool& isEof);
    void reset();

private:
    z::string getText(const bool& rw);
    TokenData token(ParserContext& pctx, const int& id, const bool& rw);
    void newLine();
    void dump(const z::string& x) const;

private:
    void send(ParserContext& pctx, const int& id);
    bool trySendId(ParserContext& pctx, const z::Ast::TypeSpec* typeSpec);
    void sendId(ParserContext& pctx);
    void sendLessThan(ParserContext& pctx);
    void sendOpenCurly(ParserContext& pctx);
    void sendReturn(ParserContext& pctx);

private:
    // this function is generated by re2c
    void lex(ParserContext& pctx);

private:
    Parser& _parser;
    int _lastToken;
    static const char* reservedWords[];

private:
    int _cond;
    int _state;

    char* _buffer;
    char* _sol;
    char* _start;
    char* _text;
    char* _marker;
    char* _cursor;
    char* _limit;
    char* _bufferEnd;

    int _row;
    char  _yych;
    unsigned int _yyaccept;
};

void z::Lexer::Impl::newLine() {
    _row++;
    _sol = _cursor;
}

z::string z::Lexer::Impl::getText(const bool& rw) {
    if(_text > 0) {
        char* t = _text;
        if(rw) {
            _text = 0;
        }
        return TokenData::getText(t, _cursor-1);
    }
    return TokenData::getText(_start, _cursor);
}

z::TokenData z::Lexer::Impl::token(ParserContext& pctx, const int& id, const bool& rw) {
    z::string txt = getText(rw);
    return TokenData::createT(pctx.factory.filename(), id, _row, _cursor-_sol, txt);
}

void z::Lexer::Impl::send(ParserContext& pctx, const int& id) {
    TokenData td = token(pctx, id, true);
    _parser.feed(pctx, td);
    _lastToken = td.id();
}

inline bool z::Lexer::Impl::trySendId(ParserContext& pctx, const z::Ast::TypeSpec* typeSpec) {
    if(!typeSpec)
        return false;

    if(dynamic_cast<const z::Ast::TemplateDecl*>(typeSpec) != 0) {
        send(pctx, ZENTOK_TEMPLATE_TYPE);
        return true;
    }

    if(dynamic_cast<const z::Ast::StructDefn*>(typeSpec) != 0) {
        send(pctx, ZENTOK_STRUCT_TYPE);
        return true;
    }
    if(dynamic_cast<const z::Ast::Routine*>(typeSpec) != 0) {
        send(pctx, ZENTOK_ROUTINE_TYPE);
        return true;
    }
    if(dynamic_cast<const z::Ast::Function*>(typeSpec) != 0) {
        send(pctx, ZENTOK_FUNCTION_TYPE);
        return true;
    }
    if(dynamic_cast<const z::Ast::EventDecl*>(typeSpec) != 0) {
        send(pctx, ZENTOK_EVENT_TYPE);
        return true;
    }
    if(dynamic_cast<const z::Ast::TypeSpec*>(typeSpec) != 0) {
        send(pctx, ZENTOK_OTHER_TYPE);
        return true;
    }
    return false;
}

inline void z::Lexer::Impl::sendId(ParserContext& pctx) {
    z::string txt = getText(false);
    z::Ast::Token tok(pctx.factory.filename(), 0, 0, txt);

    if(_lastToken == ZENTOK_SCOPE) {
        const z::Ast::TypeSpec* child = pctx.factory.unit().currentTypeRefHasChild(tok);
        if(child) {
            if(trySendId(pctx, child))
                return;
        }
    }

    if(trySendId(pctx, pctx.factory.hasRootTypeSpec(tok)))
        return;

    for(int i = 0; reservedWords[i][0] != 0; ++i) {
        const char* res = reservedWords[i];
        if(tok.string() == res) {
            return send(pctx, ZENTOK_RESERVED);
        }
    }

    send(pctx, ZENTOK_ID);
}

inline void z::Lexer::Impl::sendLessThan(ParserContext& pctx) {
    if(_lastToken == ZENTOK_TEMPLATE_TYPE) {
        return send(pctx, ZENTOK_TLT);
    }
    send(pctx, ZENTOK_LT);
}

inline void z::Lexer::Impl::sendOpenCurly(ParserContext& pctx) {
    if(pctx.factory.unit().isStructExpected() || pctx.factory.unit().isPointerToStructExpected() || pctx.factory.unit().isListOfStructExpected() || pctx.factory.unit().isListOfPointerToStructExpected()) {
        if((_lastToken != ZENTOK_STRUCT_TYPE) && (_lastToken != ZENTOK_STRUCT)) {
            send(pctx, ZENTOK_STRUCT);
        }
    }

    if(pctx.factory.unit().isFunctionExpected()) {
        if((_lastToken != ZENTOK_FUNCTION_TYPE) && (_lastToken != ZENTOK_FUNCTION)) {
            send(pctx, ZENTOK_FUNCTION);
        }
    }
    send(pctx, ZENTOK_LCURLY);
}

inline void z::Lexer::Impl::sendReturn(ParserContext& pctx) {
    const z::Ast::RoutineDefn* rd = 0;
    const z::Ast::RootFunctionDefn* rfd = 0;
    const z::Ast::ChildFunctionDefn* cfd = 0;
    for(z::Ast::Unit::TypeSpecStack::const_reverse_iterator it = pctx.factory.unit().typeSpecStack().rbegin(); it != pctx.factory.unit().typeSpecStack().rend(); ++it) {
        const z::Ast::TypeSpec& ts = it->get();
        if((rd = dynamic_cast<const z::Ast::RoutineDefn*>(z::ptr(ts))) != 0) {
            return send(pctx, ZENTOK_RRETURN);
        }
        if((rfd = dynamic_cast<const z::Ast::RootFunctionDefn*>(z::ptr(ts))) != 0) {
            return send(pctx, ZENTOK_FRETURN);
        }
        if((cfd = dynamic_cast<const z::Ast::ChildFunctionDefn*>(z::ptr(ts))) != 0) {
            return send(pctx, ZENTOK_FRETURN);
        }
    }
    TokenData pos = token(pctx, 0, false);
    throw z::Exception("Lexer", zfmt(t2t(pos), "Invalid return in lexer"));
}

inline void z::Lexer::Impl::reset() {
    _cond = 0;
    _state = -1;

    _sol = _buffer;
    _start = _buffer;
    _text = _buffer;
    _marker = _buffer;
    _cursor = _buffer;
    _limit = _buffer;

    _row = 1;
    _yych = 0;
    _yyaccept = 0;
}

inline z::Lexer::Impl::Impl(Parser& parser) : _parser(parser), _lastToken(0) {
    _buffer = 0;
    _bufferEnd = 0;
    reset();
}

inline z::Lexer::Impl::~Impl() {
    if(_buffer)
        free(_buffer);
    _buffer = 0;
}

inline void z::Lexer::Impl::dump(const z::string& x) const {
    unused(x);
    //printf("%s: buffer %lu, bufferEnd %lu, start %lu, marker %lu, cursor %lu, limit %lu, limit-cursor %ld, text %lu, text '%s'\n",
    //    z::s2e(x).c_str(), (unsigned long)_buffer, (unsigned long)_bufferEnd, (unsigned long)_start, (unsigned long)_marker, (unsigned long)_cursor, (unsigned long)_limit, _limit - _cursor, (unsigned long)_text, _text);
}

void z::Lexer::Impl::push(ParserContext& pctx, const char* input, std::streamsize inputSize, const bool& isEof) {
    /*
     * We need a small overhang after EOF on the stream which is
     * equal to the length of the largest keyword (maxFill). This is
     * slightly annoying because maxFill can only be known after re2c
     * does its thing. Practically though, maxFill is never bigger than
     * the longest keyword. A good way to get this value is to run:
     * grep "cursor - start" lexerGen.hpp
     * where lexerGen.hpp is the generated file. You will get lines like:
     * if ((limit - cursor) < 2) goto do_fill;
     * if ((limit - cursor) < 10) goto do_fill;
     * Now set maxFill to the largest RHS value among all the lines matched.
     * Currently it is 10.
     */
    const std::streamsize maxFill = isEof?10:0;

    /*
     * When we get here, we have a partially
     * consumed buffer which is in the following state:
     *                                                                  last valid char        last valid buffer spot
     *                                                                  v                      v
     * +---------+----------+-----+--------+---------------+-------------+----------------------+
     * ^         ^          ^     ^        ^               ^             ^                      ^
     * buffer    sol        start text     marker          cursor        limit                  bufferEnd
     *
     * We need to stretch the buffer (if required) and concatenate the new chunk of input to it
     *
     */
    std::streamsize required  = inputSize + maxFill;
    std::streamsize used      = _limit - _buffer;
    std::streamsize needed    = used + required;
    std::streamsize allocated = _bufferEnd - _buffer;

    dump("push(1)");

    if(allocated < needed) {
        std::streamsize solOffset    = _sol    - _buffer;
        std::streamsize startOffset  = _start  - _buffer;
        std::streamsize textOffset   = _text?(_text - _buffer):0;
        std::streamsize markerOffset = _marker - _buffer;
        std::streamsize cursorOffset = _cursor - _buffer;
        std::streamsize limitOffset  = _limit  - _buffer;

        _buffer = (inputChar_t*)realloc(_buffer, (size_t)needed);
        _bufferEnd = _buffer + needed;

        _sol    = _buffer + solOffset;
        _start  = _buffer + startOffset;
        _text   = _text?(_buffer + textOffset):0;
        _marker = _buffer + markerOffset;
        _cursor = _buffer + cursorOffset;
        _limit  = _buffer + limitOffset;
    }

    dump("push(2)");

    assert(_buffer <= _limit);
    assert(_limit <= _bufferEnd);
    assert((_limit + required) <= _bufferEnd);
    memcpy(_limit, input, (size_t)inputSize);
    _limit += inputSize;
    dump("push(3)");
    assert(_limit <= _bufferEnd);
    memset(_limit, 0, _bufferEnd - _limit + 0);
    _limit += maxFill;
    assert(_limit <= _bufferEnd);

    dump("push(4)");

    lex(pctx);

    dump("push(5)");

    //  Once we get here, we can get rid of everything before start and after limit.
    char* start = _start;
    if(_text < _start)
        start = _text;
    std::streamsize consumed = start - _buffer;
    if(consumed > 0) {
        memmove(_buffer, start, _limit - start);
        _start -= consumed;
        _text -= (_text > 0)?consumed:0;
        _marker -= consumed;
        _cursor -= consumed;
        _limit -= consumed;
    }
    dump("push(6)");
}

z::Lexer::Lexer(Parser& parser) : _impl(0) {_impl = new Impl(parser);}
z::Lexer::~Lexer() {delete _impl;}
void z::Lexer::push(ParserContext& pctx, const char* buffer, const std::streamsize& len, const bool& isEof) {return z::ref(_impl).push(pctx, buffer, len, isEof);}
void z::Lexer::reset() {return z::ref(_impl).reset();}

//-------------------------------------------------
// All keywords that are not used by zen, but are reserved because
// 1. they may have a meaning in the generated language.
// 2. zen might use it later
const char* z::Lexer::Impl::reservedWords[] = {
    "protected"    ,
    "new"          ,
    "delete"       ,
    "create"       ,
    "insert"       ,
    "remove"       ,
    "class"        ,
    "each"         ,
    "throw"        ,
    "catch"        ,
    "try"          ,
    "raise"        ,
    "lambda"       ,
    "api"          ,
    "inline"       ,
    "static"       ,
    "virtual"      ,
    "pure"         ,
    "override"     ,
    "implements"   ,
    "interface"    ,
    "base"         ,
    "parent"       ,
    "extends"      ,
    "union"        ,
    "system"       ,
    "plain"        ,
    "sequence"     ,
    "continuation" ,
    "closure"      ,
    "iterate"      ,
    "mutable"      ,
    "local"        ,
    "shared"       ,
    "any"          ,
    "def"          ,
    "grammar"      ,
    "parser"       ,
    "lexer"        ,
    "not"          ,
    "and"          ,
    "or"           ,
    "xor"          ,
    "export"       ,
    "import"       ,
    "owner"        ,
    "log"          ,
    "debug"        ,
    "write"        ,
    "exit"         ,
    "quit"         ,
    "link"         ,
    "join"         ,
    "id"           ,
    "assign"       ,
    "query"        ,
    "scope"        ,
    "\0"           // End of list marker. Must be here.
};

// the lex() function
#include "lexerGen.hpp"
