#include "base/pch.hpp"
#include "base/zenlang.hpp"
#include "lexer.hpp"
#include "NodeFactory.hpp"
#include "parserGen.h"

// the char width could be 8 bit, 16, or 32 in future.
typedef char inputChar_t;

class Lexer::Impl {
public:
    inline Impl(Parser& parser);
    inline ~Impl();
    void push(Ast::NodeFactory& factory, const char* _buffer, size_t len, const bool& isEof);
    void reset();

private:
    TokenData token(const int& id);
    void newLine();
    void dump(const std::string& x) const;

private:
    void send(Ast::NodeFactory& factory, const int& id);
    bool trySendId(Ast::NodeFactory& factory, const Ast::TypeSpec* typeSpec);
    void sendId(Ast::NodeFactory& factory);
    void sendLessThan(Ast::NodeFactory& factory);
    void sendOpenCurly(Ast::NodeFactory& factory);
    void sendReturn(Ast::NodeFactory& factory);

private:
    // this function is generated by re2c
    void lex(Ast::NodeFactory& factory);

private:
    Parser& _parser;
    int _lastToken;
    static const char* reservedWords[];

private:
    int _cond;
    int _state;

    char* _buffer;
    char* _sol;
    char* _start;
    char* _text;
    char* _marker;
    char* _cursor;
    char* _limit;
    char* _bufferEnd;

    int _row;
    char  _yych;
    unsigned int _yyaccept;
};

void Lexer::Impl::newLine() {
    _row++;
    _sol = _cursor;
}

TokenData Lexer::Impl::token(const int& id) {
    if(_text > 0) {
        char* t = _text;
        _text = 0;
        return TokenData::createT(id, _row, _cursor-_sol, t, _cursor-1);
    }
    return TokenData::createT(id, _row, _cursor-_sol, _start, _cursor);
}

void Lexer::Impl::send(Ast::NodeFactory& factory, const int& id) {
    TokenData td = token(id);
    _parser.feed(factory, td);
    _lastToken = td.id();
}

inline bool Lexer::Impl::trySendId(Ast::NodeFactory& factory, const Ast::TypeSpec* typeSpec) {
    if(!typeSpec)
        return false;

    if(dynamic_cast<const Ast::TemplateDecl*>(typeSpec) != 0) {
        send(factory, ZENTOK_TEMPLATE_TYPE);
        return true;
    }

    if(dynamic_cast<const Ast::StructDefn*>(typeSpec) != 0) {
        send(factory, ZENTOK_STRUCT_TYPE);
        return true;
    }
    if(dynamic_cast<const Ast::Routine*>(typeSpec) != 0) {
        send(factory, ZENTOK_ROUTINE_TYPE);
        return true;
    }
    if(dynamic_cast<const Ast::Function*>(typeSpec) != 0) {
        send(factory, ZENTOK_FUNCTION_TYPE);
        return true;
    }
    if(dynamic_cast<const Ast::EventDecl*>(typeSpec) != 0) {
        send(factory, ZENTOK_EVENT_TYPE);
        return true;
    }
    if(dynamic_cast<const Ast::TypeSpec*>(typeSpec) != 0) {
        send(factory, ZENTOK_OTHER_TYPE);
        return true;
    }
    return false;
}

inline void Lexer::Impl::sendId(Ast::NodeFactory& factory) {
    Ast::Token td = token(0);

    if(_lastToken == ZENTOK_SCOPE) {
        const Ast::TypeSpec* child = factory.ctx().currentTypeRefHasChild(td);
        if(child) {
            if(trySendId(factory, child))
                return;
        }
    }

    if(trySendId(factory, factory.ctx().hasRootTypeSpec(td)))
        return;

    for(int i = 0; reservedWords[i][0] != 0; ++i) {
        const char* res = reservedWords[i];
        if(td.string() == res) {
            return send(factory, ZENTOK_RESERVED);
        }
    }

    send(factory, ZENTOK_ID);
}

inline void Lexer::Impl::sendLessThan(Ast::NodeFactory& factory) {
    if(_lastToken == ZENTOK_TEMPLATE_TYPE) {
        return send(factory, ZENTOK_TLT);
    }
    send(factory, ZENTOK_LT);
}

inline void Lexer::Impl::sendOpenCurly(Ast::NodeFactory& factory) {
    if(factory.ctx().isStructExpected() || factory.ctx().isPointerToStructExpected() || factory.ctx().isListOfStructExpected() || factory.ctx().isListOfPointerToStructExpected()) {
        if((_lastToken != ZENTOK_STRUCT_TYPE) && (_lastToken != ZENTOK_STRUCT)) {
            send(factory, ZENTOK_STRUCT);
        }
    }

    if(factory.ctx().isFunctionExpected()) {
        if((_lastToken != ZENTOK_FUNCTION_TYPE) && (_lastToken != ZENTOK_FUNCTION)) {
            send(factory, ZENTOK_FUNCTION);
        }
    }
    send(factory, ZENTOK_LCURLY);
}

inline void Lexer::Impl::sendReturn(Ast::NodeFactory& factory) {
    const Ast::RoutineDefn* rd = 0;
    const Ast::RootFunctionDefn* rfd = 0;
    const Ast::ChildFunctionDefn* cfd = 0;
    for(Ast::Context::TypeSpecStack::const_reverse_iterator it = factory.ctx().typeSpecStack().rbegin(); it != factory.ctx().typeSpecStack().rend(); ++it) {
        const Ast::TypeSpec* ts = *it;
        if((rd = dynamic_cast<const Ast::RoutineDefn*>(ts)) != 0) {
            return send(factory, ZENTOK_RRETURN);
        }
        if((rfd = dynamic_cast<const Ast::RootFunctionDefn*>(ts)) != 0) {
            return send(factory, ZENTOK_FRETURN);
        }
        if((cfd = dynamic_cast<const Ast::ChildFunctionDefn*>(ts)) != 0) {
            return send(factory, ZENTOK_FRETURN);
        }
    }
    throw z::Exception("Invalid return in lexer\n");
}

inline void Lexer::Impl::reset() {
    _cond = 0;
    _state = -1;

    _sol = _buffer;
    _start = _buffer;
    _text = _buffer;
    _marker = _buffer;
    _cursor = _buffer;
    _limit = _buffer;

    _row = 1;
    _yych = 0;
    _yyaccept = 0;
}

inline Lexer::Impl::Impl(Parser& parser) : _parser(parser), _lastToken(0) {
    _buffer = 0;
    _bufferEnd = 0;
    reset();
}

inline Lexer::Impl::~Impl() {
    if(_buffer)
        free(_buffer);
    _buffer = 0;
}

inline void Lexer::Impl::dump(const std::string& x) const {
//    trace("%s: buffer %lu, bufferEnd %lu, start %lu, marker %lu, cursor %lu, limit %lu, limit-cursor %ld, text '%s'\n",
//           x.c_str(), (unsigned long)_buffer, (unsigned long)_bufferEnd, (unsigned long)_start, (unsigned long)_marker, (unsigned long)_cursor, (unsigned long)_limit, _limit - _cursor, _buffer);
}

// the lex() function
#include "lexerGen.hpp"

void Lexer::Impl::push(Ast::NodeFactory& factory, const char* input, size_t inputSize, const bool& isEof) {
    trace("push(0): isEof %d, inputSize %lu, input '%s'\n", isEof, inputSize, input);

    /*
     * We need a small overhang after EOF on the stream which is
     * equal to the length of the largest keyword (maxFill). This is
     * slightly annoying because maxFill can only be known after re2c
     * does its thing. Practically though, maxFill is never bigger than
     * the longest keyword. A good way to get this value is to run:
     * grep "cursor - start" lexerGen.hpp
     * where lexerGen.hpp is the generated file. You will get lines like:
     * if ((limit - cursor) < 2) goto do_fill;
     * if ((limit - cursor) < 10) goto do_fill;
     * Now set maxFill to the largest RHS value among all the lines matched.
     * Currently it is 10.
     */
    const size_t maxFill = isEof?10:0;

    /*
     * When we get here, we have a partially
     * consumed buffer which is in the following state:
     *                                                                  last valid char        last valid buffer spot
     *                                                                  v                      v
     * +---------+----------+-----+--------+---------------+-------------+----------------------+
     * ^         ^          ^     ^        ^               ^             ^                      ^
     * buffer    sol        start text     marker          cursor        limit                  bufferEnd
     *
     * We need to stretch the buffer (if required) and concatenate the new chunk of input to it
     *
     */
    size_t required  = inputSize + maxFill;
    size_t used      = _limit - _buffer;
    size_t needed    = used + required;
    size_t allocated = _bufferEnd - _buffer;

    dump("push(1)");
//    trace("maxFill %lu, required %lu, used %lu, needed %lu, allocated %lu\n", maxFill, required, used, needed, allocated);

    if(allocated < needed) {
        size_t solOffset    = _sol    - _buffer;
        size_t startOffset  = _start  - _buffer;
        size_t textOffset   = _text?(_text - _buffer):0;
        size_t markerOffset = _marker - _buffer;
        size_t cursorOffset = _cursor - _buffer;
        size_t limitOffset  = _limit  - _buffer;

        _buffer = (inputChar_t*)realloc(_buffer, needed);
        _bufferEnd = _buffer + needed;

        _sol    = _buffer + solOffset;
        _start  = _buffer + startOffset;
        _text   = textOffset?(_buffer + textOffset):0;
        _marker = _buffer + markerOffset;
        _cursor = _buffer + cursorOffset;
        _limit  = _buffer + limitOffset;
    }

    dump("push(2)");

    assert(_buffer <= _limit);
    assert(_limit <= _bufferEnd);
    assert((_limit + required) <= _bufferEnd);
    memcpy(_limit, input, inputSize);
    _limit += inputSize;
    assert(_limit <= _bufferEnd);
    memset(_limit, 0, _bufferEnd - _limit + 1);
    _limit += maxFill;
    assert(_limit <= _bufferEnd);

//    for(char* x = _buffer; x <= _bufferEnd; x++) {
//        trace("%ld %d %c\n", x - _buffer + 1, *x, *x);
//    }

    dump("push(3)");

    lex(factory);

    dump("push(4)");

    //  Once we get here, we can get rid of everything before start and after limit.
    size_t consumed = _start - _buffer;
//    trace("consumed %lu, maxFill %lu, *cursor %d, *cursor %c\n", consumed, maxFill, *_cursor, *_cursor);
    if(consumed > 0) {
        memmove(_buffer, _start, _limit - _start);
        _marker -= consumed;
        _cursor -= consumed;
        _limit -= consumed;
        _start -= consumed;
    }
    dump("push(5)");
}

Lexer::Lexer(Parser& parser) : _impl(0) {_impl = new Impl(parser);}
Lexer::~Lexer() {delete _impl;}
void Lexer::push(Ast::NodeFactory& factory, const char* buffer, const size_t& len, const bool& isEof) {return z::ref(_impl).push(factory, buffer, len, isEof);}
void Lexer::reset() {return z::ref(_impl).reset();}

//-------------------------------------------------
// All keywords that are not used by zen, but are reserved because
// 1. they may have a meaning in the generated language.
// 2. zen might use it later
const char* Lexer::Impl::reservedWords[] = {
    "protected"    ,
    "new"          ,
    "delete"       ,
    "create"       ,
    "insert"       ,
    "remove"       ,
    "class"        ,
    "each"         ,
    "throw"        ,
    "catch"        ,
    "try"          ,
    "raise"        ,
    "lambda"       ,
    "api"          ,
    "inline"       ,
    "static"       ,
    "virtual"      ,
    "pure"         ,
    "override"     ,
    "implements"   ,
    "interface"    ,
    "base"         ,
    "parent"       ,
    "extends"      ,
    "union"        ,
    "system"       ,
    "plain"        ,
    "sequence"     ,
    "continuation" ,
    "closure"      ,
    "iterate"      ,
    "mutable"      ,
    "local"        ,
    "shared"       ,
    "any"          ,
    "def"          ,
    "grammar"      ,
    "parser"       ,
    "lexer"        ,
    "not"          ,
    "and"          ,
    "or"           ,
    "xor"          ,
    "export"       ,
    "import"       ,
    "owner"        ,
    "log"          ,
    "debug"        ,
    "write"        ,
    "exit"         ,
    "quit"         ,
    "link"         ,
    "join"         ,
    "id"           ,
    "assign"       ,
    "query"        ,
    "scope"        ,
    "\0"           // End of list marker. Must be here.
};
